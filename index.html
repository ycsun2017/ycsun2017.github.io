<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Yanchao Sun's Homepage</title>
    <!-- Website Styles -->
    <link rel="stylesheet" href="files/style.css" type="text/css" media="screen" />
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,700,400italic' rel='stylesheet' type='text/css' />
    <link href='http://fonts.googleapis.com/css?family=Roboto+Slab:400,700' rel='stylesheet' type='text/css' />
    <link rel="icon" href="/files/favicon.ico">
    <script src="https://kit.fontawesome.com/abc80a1841.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="files/academicons/css/academicons.min.css"/>

    <style>
        html {
            scroll-behavior: smooth;
        }
        .news-row {
            height: 50px;
            vertical-align: top;
        }
        .news-date {
            color: blue;
            white-space: nowrap;
        }
    </style>
    
</head>

<body>
    <div id="wrapper">

        <div id="header">
            <div class="inner">
                <div class="logo">
                    <img src="files/umd.jpg" alt="Purity" height="60">
                </div>
                <div class="log">
                    <p>
                        <font size="+2">Yanchao Sun</font>
                    </p>
                </div>
                <div class="nav">
                    <ul>
                        <li class="current"><a href="index.html">Home</a></li>
                        <li><a href="#news">News</a></li>
                        <li><a href="#pubs">Publications</a></li>
                        <li><a href="https://drive.google.com/file/d/1AkXDL60BwIz43Es_RHCh-LCi61q27xEA/view?usp=sharing">CV</a></li>
                    </ul>
                </div>
                <div class="clear"></div>
            </div>
        </div>

        <div id="main">
            <div class="inner">

                <div class="one_third">
                    <img src="files/me.png" width="200">
                    <!-- <br> <br> Ph.D. Candidate <br> <br>
                    <a href="https://https://www.umd.edu/" target="_blank" rel="nofollow">University of Maryland, College Park</a> <br>
                    <a href="https://https://www.cs.umd.edu/" target="_blank" rel="nofollow">Department of Computer Science</a> <br> -->
                    <br><br><b><font size="+1.5">Yanchao Sun (孙妍超)</font></b> <br><br>
                    ycsun1531 at gmail dot com <br>
                    <i class="ai ai-google-scholar-square ai-1x"></i> <a href="https://scholar.google.com/citations?user=bloBY_QAAAAJ&hl=en" target="_blank" rel="nofollow">Google Scholar</a><br>
                    <i class="fa-brands fa-github-square fa-1x"></i> <a href="https://github.com/ycsun2017" target="_blank" rel="nofollow">Github</a><br>
                    <i class="fa-brands fa-linkedin"></i> <a href="https://www.linkedin.com/in/yanchao-sun-50440a1a4/" target="_blank" rel="nofollow">LinkedIn</a>
                </div>


                <h3>About me</h3>
                <div class="two_third last"> 
                    <p>
                        I am curretly a machine learning research engineer at Apple AI/ML. 
                        I work on foundation models, with a focus of LLM reasoning and reinforcement learning. 
                    </p>

                    <p>
                        Prior to Apple, I was a research scientist at JPMorgan AI Research focused on building LLM-powered autonomous agents and foundation models for finance.
                    </p>

                    <p> I obtained my Ph.D. degree from the <a href="https://www.umd.edu/" target="_blank" rel="nofollow">University of Maryland, College Park</a>, 
                        where I am fortunate to be advised by <a href="http://furong-huang.com/" target="_blank" rel="nofollow">Prof. Furong Huang</a>. 
                        My Ph.D. research mainly focuses on reinforcement learning (RL) and trustworthy machine learning.
                        Here is my thesis: <a href="https://www.proquest.com/openview/46cebe8ec0f46d11f043ec5794236243/1?pq-origsite=gscholar&cbl=18750&diss=y">thesis</a>.
                        <!-- My long-term goal is to make RL agents more robust and more efficient. -->
                        <!-- Before that, I received my Bachelor’s degree in Computer Science from <a href="https://en.scu.edu.cn/">Sichuan University</a>,  -->
                        <!-- where I closely worked with <a href="http://yneversky.sinaapp.com">Prof. Ning Yang</a> on data mining and recommender systems. -->
                    </p>

                    <!-- <p> 
                        In the past summer, I was excited to work as a research intern in <a href="https://www.microsoft.com/en-us/research/">Microsoft</a> with <a href="https://www.microsoft.com/en-us/research/people/shuama/">Dr. Shuang Ma</a>, working on pretraining methods for RL.
                        I also had wonderful experience working as a research intern in the AI Research team of <a href="https://www.jpmorganchase.com">JPMorgan Chase & Co.</a> under the supervision of <a href="https://www.linkedin.com/in/sumitra-ganesh-0379853/">Dr. Sumitra Ganesh</a>; 
                        We worked on certifiable defenses against communication attacks in Multi-agent RL (<a href="https://arxiv.org/abs/2206.10158">paper</a>).
                        In the summer of 2020, I interned at <a href="https://unity.com">Unity Technologies</a> with my mentor <a href="https://www.linkedin.com/in/andrew-cohen-17a7aa15b/">Dr. Andrew Cohen</a>; 
                        We investigated knowledge transfer across tasks (<a href="https://arxiv.org/abs/2201.00248">paper</a>).
                    </p> -->

                    <!-- I am open to research collaborations! Here are my <a href="files/CV_Yanchao_Sun.pdf">CV</a> and my <a href="files/Research_Statement.pdf">Research Statement</a>.  -->

                    <!-- <p><font color="red">I am looking for full-time opportunities. </font> Here are my <a href="files/CV_Yanchao_Sun.pdf">CV</a> and my <a href="files/Research_Statement.pdf">Research Statement</a>. Please feel free to contact me if you think I could be a good fit. </p> -->
                </div>

                <div class="divider line"></div>


                <h3 id="news">
                    News and Highlights
                    <a href="#top" style="font-size: 0.8em; margin-left: 10px;">Back to Top</a>
                </h3>
                <div>
                    <ul class="list square">
                        <table>
                            <tr class="news-row">
                                <td class="news-date">[2025.3]</td>
                                <td>
                                    Our paper on token-level DPO was accepted by ICLR 2025. 
                                    <a href="https://arxiv.org/abs/2410.04350">Paper Link.</a> 
                                    Great work by our intern <a href="https://scholar.google.com/citations?user=UCOOmcEAAAAJ&hl=en">Aiwei Liu</a>!
                                </td>
                            </tr>

                            <tr class="news-row">
                                <td class="news-date">[2025.3]</td>
                                <td>
                                    I'm honored to give a talk at the <a href="https://en.wikipedia.org/wiki/Steve_Jobs_Theater">Steve Jobs Theater</a>! 
                                </td>
                            </tr>

                            <tr class="news-row">
                                <td class="news-date">[2025.1]</td>
                                <td>
                                    My first paper at Apple, which presents an easy-to-use LLM Agent Benchmark, was accepted by NAACL 2025. Try it out at:
                                    <a href="https://github.com/apple/axlearn/tree/main/docs/research/mmau">Project Page</a>.
                                </td>
                            </tr>

                            <tr class="news-row">
                                <td class="news-date">[2024.7]</td>
                                <td>
                                    Our paper on LLM agent with offline learning got accepted by the 1st COLM conference.
                                    Thanks to all collaborators at JPMorgan!
                                    <a href="https://arxiv.org/abs/2310.14403">Link</a>.
                                </td>
                            </tr>

                            <tr class="news-row">
                                <td class="news-date">[2024.1]</td>
                                <td>
                                    We have 4 papers accepted by ICLR 2024: <a href="https://arxiv.org/abs/2402.12673">1 spotlight</a>
                                    and 3 posters (<a href="https://arxiv.org/abs/2305.17342">paper 1</a>,
                                    <a href="https://arxiv.org/abs/2310.07220">paper 2</a>,
                                    <a href="https://arxiv.org/abs/2307.12062">paper 3</a>).
                                </td>
                            </tr>


                            <tr class="news-row">
                                <td class="news-date">[2023.9]</td>
                                <td>
                                    Two papers accepted by NeurIPS 2023: 
                                    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/7bd4a7d0e6773072c2e3c77b11d93065-Paper-Conference.pdf">1 spotlight</a>
                                    and <a href="https://arxiv.org/abs/2306.13229">1 poster</a>.
                                </td>
                            </tr>

                            <tr class="news-row">
                                <td class="news-date">[2023.7]</td>
                                <td>
                                    Our paper about generalist agent has been accepted by ICCV 2023:
                                    <a href="https://arxiv.org/abs/2307.07909">Paper Link</a>.
                                </td>
                            </tr>

                            <tr class="news-row">
                                <td class="news-date">[2023.7]</td>
                                <td>
                                    I am co-organizing the ICCV 2023 workshop <i>PerDream: PERception, DEcision making, and REAsoning through Multimodal foundational modeling</i>. 
                                    Visit our <a href="https://sites.google.com/view/perdream/home">website</a> for details.
                                </td>
                            </tr>
                              
                            <tr class="news-row">
                                <td class="news-date">[2023.1]</td>
                                <td>
                                    We have 3 papers accepted by ICLR 2023 — 
                                    <a href="https://arxiv.org/abs/2301.09816">1 spotlight</a>
                                    and 2 posters 
                                    (<a href="https://arxiv.org/abs/2206.10158">paper 1</a>, 
                                    <a href="https://arxiv.org/abs/2302.03015">paper 2</a>)!
                                </td>
                            </tr>
                              
                            <tr class="news-row">
                                <td class="news-date">[2022.11]</td>
                                <td>
                                    I am co-organizing the first <i>Reincarnating RL</i> workshop at ICLR 2023.
                                    Learn more at <a href="https://reincarnating-rl.github.io/">reincarnating-rl.github.io</a>.
                                </td>
                            </tr>
                              
                            <tr class="news-row">
                                <td class="news-date">[2022.09]</td>
                                <td>
                                    Three of our papers were accepted to NeurIPS 2022. 
                                    <a href="https://arxiv.org/abs/2211.00824"> 1 spotlight</a> and 2 posters
                                    (<a href="https://arxiv.org/abs/2210.05927">paper 1</a>
                                    <a href="https://arxiv.org/abs/2210.07636">paper 2</a>)
                                </td>
                            </tr>
                              
                            <tr class="news-row">
                                <td class="news-date">[2022.01]</td>
                                <td>
                                    Two papers accepted to ICLR 2022! Check them out: 
                                    <a href="https://openreview.net/forum?id=JM2kFbJvvI">adversarial RL</a> and 
                                    <a href="https://openreview.net/forum?id=7KdAoOsI81C">transfer RL</a>.
                                </td>
                            </tr>
                              
                            <tr class="news-row">
                                <td class="news-date">[2021.12]</td>
                                <td>
                                    Our paper <i>"Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL"</i> received the 
                                    <b>Best Paper Award</b> at the <a href="https://sites.google.com/view/safe-robust-control/home">SafeRL 2021 Workshop</a>!
                                </td>
                            </tr>

                            <!-- <tr style="height:30px;">
                                <td style="vertical-align: top;">
                                    <font color="blue">[2021.12]&nbsp;&nbsp;&nbsp; </font>
                                </td>
                                <td style="vertical-align: top;"> 
                                    Presented our papers in the NeurIPS 2021 DeepRL and SafeRL workshops.
                                </td>
                            </tr>

                            <tr style="height:30px;">
                                <td style="vertical-align: top;">
                                    <font color="blue">[2021.06]&nbsp;&nbsp;&nbsp; </font>
                                </td>
                                <td style="vertical-align: top;"> 
                                    Started a research internship at JPMorgan Chase & Co., under the supervision of <a href="https://www.linkedin.com/in/sumitra-ganesh-0379853">Dr. Sumitra Ganesh</a>.
                                </td>
                            </tr> -->

                            <!-- <tr style="height:30px;">
                                <td style="vertical-align: top;">
                                    <font color="blue">[2021.01]&nbsp;&nbsp;&nbsp; </font>
                                </td>
                                <td style="vertical-align: top;"> 
                                    Our paper on <a href="https://openreview.net/forum?id=9r30XCjf5Dt">poisoning RL</a> was accepted by ICLR 2021.
                                </td>
                            </tr> -->
                            
        
                        </table>
                    </ul>

                </div>
                <table>

                <div class="divider line"></div>


                <h3 id="pubs">
                    Selected Publications
                    <a href="#top" style="font-size: 0.8em; margin-left: 10px;">Back to Top</a>
                </h3>
                Please see <a href="https://scholar.google.com/citations?user=bloBY_QAAAAJ">here</a> for a full list of my publications. <br><br>

                <div>
                    <table>
                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">NAACL 2025 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /></font>
                            </td>
                            <td style="vertical-align: top;">
                                <font size="+1">MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains.</font><br /><br />
                                Guoli Yin*, Haoping Bai*, Shuang Ma*, Feng Nan, <b>Yanchao Sun</b>, et al.<br />
                                <i>In Proceedings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2025.</i>
                                <br /><br />
                                <a class="box" href="https://arxiv.org/abs/2407.18961">Paper</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://github.com/apple/axlearn/tree/main/docs/research/mmau">Code</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://github.com/apple/axlearn/tree/main/docs/research/mmau">HTML</a>
                            <br /><br />
                            </td>
                        </tr>

                        <tr>
                            <td style="vertical-align: top;">
                              <font color="blue">COLM 2024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /></font>
                            </td>
                            <td style="vertical-align: top;">
                              <font size="+1">O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models.</font><br /><br />
                              Yuchen Xiao*, <b>Yanchao Sun*</b>, Mengda Xu, Udari Madhushani, Jared Vann, Deepeka Garg, and Sumitra Ganesh.<br />
                              <i>In The 1st Conference on Language Modeling (COLM), 2024.</i><br />
                              <i>*Equal Contribution</i><br /><br />
                              <a class="box" href="https://arxiv.org/abs/2310.14403">Paper</a>
                              <br /><br />
                            </td>
                          </tr>

                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">ICLR 2023 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /> </font>
                            </td>
                            <td style="vertical-align: top;"> 
                                <font size="+1">SMART: Self-supervised Multi-task pretrAining with contRol Transformers.</font>  <br /> 
                                <br /><b>Yanchao Sun</b>, Shuang Ma, Ratnesh Madaan, Rogerio Bonatti, Furong Huang, Ashish Kapoor<br />
                                <i>Spotlight presentation In International Conference on Learning Representations, 2023 </i> 
                                <br /><br />
                                <a class="box" target="https://arxiv.org/abs/2301.09816">Paper</a>  
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" target="https://github.com/microsoft/smart">Code</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" target="https://drive.google.com/file/d/1i7szNeZN7v81HR630tFGfsn8HpuZiL6T/view?usp=sharing">Models</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/smart-a-generalized-pretraining-framework-for-control-tasks/">HTML</a>
                            <br /><br />
                            </td>
                        </tr>

                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">NeurIPS 2022 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /> </font>
                            </td>
                            <td style="vertical-align: top;"> 
                                <font size="+1">Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning.</font>  <br /> 
                                <br />Yongyuan Liang*, <b>Yanchao Sun*</b>, Ruijie Zheng, and Furong Huang.  (* Equal Contribution)<br />
                                <i>In the 36th Conference on Neural Information Processing Systems, 2022 </i> 
                                <br /><br />
                                <a class="box" target="https://openreview.net/pdf?id=y-E1htoQl-n">Paper</a> 
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" target="https://github.com/umd-huang-lab/WocaR-RL">Code</a>
                                <!-- &nbsp;&nbsp;&nbsp;
                                <a class="box" target="_blank">HTML</a> -->
                                <br /><br />
                            </td>
                        </tr>

                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">ICLR 2022 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /> </font>
                            </td>
                            <td style="vertical-align: top;"> <font size="+1">Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL.</font>  <br /> 
                                <br /><b>Yanchao Sun</b>, Ruijie Zheng, Yongyuan Liang, and Furong Huang.  <br />
                                <i>In International Conference on Learning Representations, 2022 </i> <br />
                                <font color="red">Best Paper Award</font> <i> in NeurIPS 2021 Workshop of <a href="https://sites.google.com/view/safe-robust-control/home">Safe and Robust Control of Uncertain Systems (SafeRL 2021)</a></i>.  <br /><br />
                                <a class="box" href="https://openreview.net/forum?id=JM2kFbJvvI">Paper</a> 
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://github.com/umd-huang-lab/paad_adv_rl">Code</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="paad/index.html">HTML</a>
                                <br /><br />
                            </td>
                        </tr>
    
                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">ICLR 2022 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /> </font>
                            </td>
                            <td style="vertical-align: top;"> 
                                <font size="+1">Transfer RL across Observation Feature Spaces via Model-Based Regularization.</font> <br /> 
                                <br /><b>Yanchao Sun</b>, Ruijie Zheng, Xiyao Wang, Andrew Cohen, and Furong Huang.  <br />
                                <i>In International Conference on Learning Representations, 2022  </i> <br /><br />
                                <a class="box" href="https://openreview.net/forum?id=7KdAoOsI81C">Paper</a> 
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://github.com/umd-huang-lab/transfer_across_obs">Code</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="transfer/index.html">HTML</a>
                                <br /><br />
                            </td>
                        </tr>

                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">ICLR 2021 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /> </font>
                            </td>
                            <td style="vertical-align: top;"> 
                                <font size="+1">Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics.</font> <br /> 
                                <br /><b>Yanchao Sun</b>, Da Huo, and Furong Huang.  <br />
                                <i>In International Conference on Learning Representations, 2021  </i> <br /><br />
                                <a class="box" href="https://arxiv.org/abs/2009.00774">Paper</a> 
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://github.com/umd-huang-lab/poison-rl">Code</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="poison/index.html">HTML</a>
                                <br /><br />
                            </td>
                        </tr>

                        <tr>
                            <td style="vertical-align: top;">
                                <font color="blue">AAAI 2021 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br /><br /> </font>
                            </td>
                            <td style="vertical-align: top;"> 
                                <font size="+1">TempLe: Learning Template of Transitions for Sample Efficient Multi-task RL.</font> <br /> 
                                <br /><b>Yanchao Sun</b>, Xiangyu Yin, and Furong Huang.  <br />
                                <i>In AAAI Conference on Artificial Intelligence, 2021  </i> <br /><br />
                                <a class="box" href="https://arxiv.org/abs/2002.06659">Paper</a> 
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="https://github.com/umd-huang-lab/template-reinforcement-learning">Code</a>
                                &nbsp;&nbsp;&nbsp;
                                <a class="box" href="temple/index.html">HTML</a>
                                <br /><br />
                            </td>
                        </tr>

                        
                        
    
                    </table>

                    Please see <a href="https://scholar.google.com/citations?user=bloBY_QAAAAJ">here</a> for a full list of my publications. <br><br>


                </div>

            </div>
            <div class="divider line"></div>
            <!-- .inner End -->
        </div>

    </div>

    </div>

</body>

</html>